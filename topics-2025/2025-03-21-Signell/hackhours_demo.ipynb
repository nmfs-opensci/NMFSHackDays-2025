{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53879bef-47c3-4419-8041-75226c305d3f",
   "metadata": {},
   "source": [
    "# Explore NOAA NODD CDR SST\n",
    "* use Virtualizarr to create a cloud-optimized virtual dataset from multiple remote NetCDF files\n",
    "* explore the virtual dataset using Holoviz tools\n",
    "* compute in parallel using Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7a1c7-7e14-48c3-80c1-8cbc8608f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bff9e0-1d70-4651-baa7-9d9e3605ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(\"s3\", anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d2eec3-4f87-487b-a591-baaffcc7bc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "oisst_files = fs.glob(\n",
    "    \"s3://noaa-cdr-sea-surface-temp-optimum-interpolation-pds/data/v2.1/avhrr/202503/oisst-avhrr-v02r01.*.nc\"\n",
    ")\n",
    "\n",
    "oisst_files = sorted([\"s3://\" + f for f in oisst_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ca1c05-2fd5-4187-97a9-aff0644028cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(oisst_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d988c-3282-4a2a-90e0-a3b81adf33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from virtualizarr import open_virtual_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b897f2-18e4-49ac-b7dc-0b74c48ebd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "so = dict(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f538c3-b35a-49da-beec-de7b2fe6ce0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "virtual_datasets = [\n",
    "    open_virtual_dataset(url, indexes={}, reader_options={\"storage_options\": so}, )\n",
    "    for url in oisst_files\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9049-0b4c-4780-8b60-3a66799ab24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4591e-f77b-4fe2-bb5d-6964825f4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this Dataset wraps a bunch of virtual ManifestArray objects directly\n",
    "virtual_ds = xr.concat(\n",
    "    virtual_datasets,\n",
    "    dim=\"time\",\n",
    "    coords=\"minimal\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"override\",\n",
    ")\n",
    "# cache the combined dataset pattern to disk, in this case using the existing kerchunk specification for reference files\n",
    "virtual_ds.virtualize.to_kerchunk('combined.json', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7573f6-e505-47cc-9a71-1bff82dafb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset('combined.json', engine='kerchunk', backend_kwargs={'storage_options':dict(remote_options=so)}, chunks={})  # normal xarray.Dataset object, wrapping dask/numpy arrays etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1495e9-b784-4884-96a3-8805a3719633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e709f2-cacf-465e-bf98-06ce005b4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hvplot.xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c60c2-cf1e-42f9-8e86-6805f6b403d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sst'].nbytes/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e858e894-74a4-4caa-a1df-7ca60a6a8ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af487bf5-0627-413f-b27b-936eb9e388bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))  #.sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0df986a-d0a8-49ac-a99d-362d737bdd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sst'][0,0,:,:].hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbde6f-a574-4ba2-9788-1bfd6f091890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259746b4-108d-4df5-b4e7-8624ae2f1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_type = 'Coiled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bd010-ff4c-4a31-8d15-7f21f5d982f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_type == 'Gateway':\n",
    "    from dask_gateway import Gateway\n",
    "    gateway = Gateway()  # instantiate Dask gateway \n",
    "    options = gateway.cluster_options()\n",
    "    cluster = gateway.new_cluster(options)\n",
    "    client = cluster.get_client()\n",
    "    cluster.adapt(minimum=4, maximum=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e552292-0651-467f-a729-e6473d2fdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cluster_type == 'Coiled':\n",
    "    import coiled\n",
    "    cluster = coiled.Cluster(\n",
    "        region=\"us-west-2\",\n",
    "        arm=True,   # run on ARM to save energy & cost\n",
    "        worker_vm_types=[\"t4g.small\"],  # cheap, small ARM instances, 2cpus, 2GB RAM\n",
    "        worker_options={'nthreads':2},\n",
    "        n_workers=4,\n",
    "        wait_for_workers=False,\n",
    "        compute_purchase_option=\"spot_with_fallback\",\n",
    "        name='hackhours_rps',   # Dask cluster name\n",
    "        software='hackhours-arm',  # Conda environment name\n",
    "        workspace='esip-lab',\n",
    "        timeout=180   # leave cluster running for 3 min in case we want to use it again\n",
    "    )\n",
    "\n",
    "    client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8b89d-3428-4689-a144-1ae0204c808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "so = dict(anon=True)\n",
    "\n",
    "\n",
    "virtual_datasets = dask.compute(*[\n",
    "    dask.delayed(open_virtual_dataset)(url, indexes={}, reader_options={\"storage_options\": so}, )\n",
    "    for url in oisst_files\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4ba3a-f94c-4226-aa1d-a4b9232c0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this Dataset wraps a bunch of virtual ManifestArray objects directly\n",
    "virtual_ds = xr.concat(\n",
    "    virtual_datasets,\n",
    "    dim=\"time\",\n",
    "    coords=\"minimal\",\n",
    "    compat=\"override\",\n",
    "    combine_attrs=\"override\",\n",
    ")\n",
    "# cache the combined dataset pattern to disk, in this case using the existing kerchunk specification for reference files\n",
    "virtual_ds.virtualize.to_kerchunk('combined.json', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd9f16a-ff25-49f7-83fd-25c6e6cdb985",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://gist.githubusercontent.com/rsignell/dd6a8d6fafcea40dfd23dd3e887fcc1e/raw/ba366821704a648ff71aa669fe07ccf503cbfd1d/sst_combined_refs.json'\n",
    "ds = xr.open_dataset(url, engine='kerchunk', backend_kwargs={'storage_options':dict(remote_options=so)}, chunks={})  # normal xarray.Dataset object, wrapping dask/numpy arrays etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412e438-0dc8-4c2b-92d0-bca375e8070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "da = ds['sst'][:3,0,:,:].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b3f85-f3c9-49c0-bcf2-02eadec9cd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds['sst'][:,0,:,:].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac566f41-1317-4e54-8676-9381a02c82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9b60d-58f1-4101-b71b-e1d14d1dca1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
